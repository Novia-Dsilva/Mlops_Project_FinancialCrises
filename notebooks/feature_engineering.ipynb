{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80eae5b0",
   "metadata": {},
   "source": [
    "**ðŸ“Š FEATURE IMPORTANCE RANKING**\n",
    "**ðŸŸ¢ðŸŸ¢ðŸŸ¢ TIER 1: CRITICAL (Must Have for Modeling)**\n",
    "Macroeconomic Stress Indicators:\n",
    "Financial_Stress_Index - Official Fed stress measure\n",
    "Corporate_Bond_Spread - Direct corporate credit risk\n",
    "TED_Spread - Banking system stress\n",
    "High_Yield_Spread - Stressed company risk premium\n",
    "Yield_Curve_Spread - Recession predictor\n",
    "\n",
    "Market Fear Indicators:\n",
    "VIX - Market fear gauge\n",
    "SP500_Return - Market momentum\n",
    "\n",
    "Economic Fundamentals:\n",
    "GDP_Growth - Economic health\n",
    "Unemployment_Rate - Labor market / recession signal\n",
    "Federal_Funds_Rate - Cost of capital\n",
    "CPI_Inflation - Price pressures\n",
    "\n",
    "Company Performance:\n",
    "{COMPANY}_Stock_Return (all 25) - Direct performance metrics\n",
    "\n",
    "Why critical: These directly measure stress, economic health, and company performance - the core of the prediction task.\n",
    "\n",
    "**ðŸŸ¢ðŸŸ¢ TIER 2: HIGH IMPORTANCE (Strong Predictive Power)**\n",
    "Consumer_Confidence - Leading consumer spending indicator\n",
    "Treasury_10Y_Yield - Benchmark borrowing rate\n",
    "{COMPANY}_Stock_Volume - Unusual activity detection\n",
    "SP500 - Market level / valuation\n",
    "Quarter - Earnings cycle alignment\n",
    "Why high: Strong relationship with economic conditions and company performance, but somewhat redundant with Tier 1.\n",
    "\n",
    "**ðŸŸ¡ TIER 3: MEDIUM IMPORTANCE (Useful Context)**\n",
    "Oil_Price - Energy costs, inflation proxy\n",
    "Trade_Balance - Economic flows\n",
    "Year - Long-term trends\n",
    "Month - Seasonal patterns\n",
    "Why medium: Provide additional context but less direct impact on individual company stress.\n",
    "\n",
    "**ðŸ”´ TIER 4: LOW IMPORTANCE (Minor or Redundant)**\n",
    "{COMPANY}_Stock_Price - Use returns instead\n",
    "DayOfWeek - Weak intraday patterns\n",
    "IsMonthEnd - Minor microstructure effect\n",
    "Unnamed: 0 - Index, not a feature\n",
    "Why low: Either redundant (stock price), weak signal (day of week), or not a feature (index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75891f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66067a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\akulc\\\\mlops_project\\\\Mlops_Project_FinancialCrises\\\\data\\\\processed\\\\merged\\\\financial_data_complete_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dfb7976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f33b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_features = df1.shape[1]\n",
    "initial_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da077cb8",
   "metadata": {},
   "source": [
    "Phase 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a0ba1",
   "metadata": {},
   "source": [
    "1A. Lag Features - Economic Indicators\n",
    "Why: Economic conditions from recent past strongly predict future stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e63ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/6] Creating lag features for economic indicators...\n",
      "   âœ… Created 25 economic lag features\n"
     ]
    }
   ],
   "source": [
    "# Create lag features for slowly-changing economic indicators\n",
    "print(\"\\n[1/6] Creating lag features for economic indicators...\")\n",
    "\n",
    "macro_lag_features = [\n",
    "    'GDP_Growth', 'Unemployment_Rate', 'CPI_Inflation',\n",
    "    'Federal_Funds_Rate', 'Consumer_Confidence'\n",
    "]\n",
    "\n",
    "lags = [1, 5, 10, 20, 60]\n",
    "\n",
    "lag_count = 0\n",
    "for feature in macro_lag_features:\n",
    "    if feature in df1.columns:\n",
    "        for lag in lags:\n",
    "            df1[f'{feature}_lag{lag}'] = df1[feature].shift(lag)\n",
    "            lag_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {lag_count} economic lag features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d95dd7",
   "metadata": {},
   "source": [
    "1B. Lag Features - Market Stress Indicators\n",
    "Why: Market stress evolves quickly - recent history matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "241dcce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/6] Creating lag features for market stress indicators...\n",
      "   âœ… Created 25 market stress lag features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[2/6] Creating lag features for market stress indicators...\")\n",
    "\n",
    "market_lag_features = [\n",
    "    'VIX', 'Corporate_Bond_Spread', 'TED_Spread', \n",
    "    'High_Yield_Spread', 'Financial_Stress_Index'\n",
    "]\n",
    "\n",
    "market_lags = [1, 2, 3, 5, 10]\n",
    "\n",
    "lag_count = 0\n",
    "for feature in market_lag_features:\n",
    "    if feature in df1.columns:\n",
    "        for lag in market_lags:\n",
    "            df1[f'{feature}_lag{lag}'] = df1[feature].shift(lag)\n",
    "            lag_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {lag_count} market stress lag features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a2ab8d",
   "metadata": {},
   "source": [
    "2. Rolling Statistics (Volatility & Momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80fc2050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/6] Creating rolling statistics (volatility & momentum)...\n",
      "   âœ… VIX rolling stats: 12 features\n",
      "   âœ… Company rolling stats: 150 features\n",
      "   âœ… Spread rolling stats: 12 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_volatility_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Return_momentum_{window}'] = \\\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_mean_{window}'] = df1[spread].rolling(window).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_max_{window}'] = df1[spread].rolling(window).max()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_mean_{window}'] = df1[spread].rolling(window).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_max_{window}'] = df1[spread].rolling(window).max()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_mean_{window}'] = df1[spread].rolling(window).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_max_{window}'] = df1[spread].rolling(window).max()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_mean_{window}'] = df1[spread].rolling(window).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_max_{window}'] = df1[spread].rolling(window).max()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_mean_{window}'] = df1[spread].rolling(window).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_max_{window}'] = df1[spread].rolling(window).max()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_mean_{window}'] = df1[spread].rolling(window).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\3157403881.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{spread}_rolling_max_{window}'] = df1[spread].rolling(window).max()\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3/6] Creating rolling statistics (volatility & momentum)...\")\n",
    "\n",
    "# A. VIX rolling statistics\n",
    "windows = [5, 10, 20, 60]\n",
    "rolling_count = 0\n",
    "\n",
    "if 'VIX' in df1.columns:\n",
    "    for window in windows:\n",
    "        df1[f'VIX_rolling_mean_{window}'] = df1['VIX'].rolling(window).mean()\n",
    "        df1[f'VIX_rolling_std_{window}'] = df1['VIX'].rolling(window).std()\n",
    "        df1[f'VIX_rolling_max_{window}'] = df1['VIX'].rolling(window).max()\n",
    "        rolling_count += 3\n",
    "\n",
    "print(f\"   âœ… VIX rolling stats: {rolling_count} features\")\n",
    "\n",
    "# B. Stock return volatility and momentum for ALL companies\n",
    "companies = ['AAPL', 'AMZN', 'BA', 'BAC', 'C', 'CAT', 'COST', 'CVX', \n",
    "             'DIS', 'GOOGL', 'GS', 'HD', 'JNJ', 'JPM', 'LIN', 'MCD', \n",
    "             'MSFT', 'NFLX', 'NVDA', 'PG', 'TSLA', 'UNH', 'WFC', 'WMT', 'XOM']\n",
    "\n",
    "rolling_count = 0\n",
    "for company in companies:\n",
    "    return_col = f'{company}_Stock_Return'\n",
    "    if return_col in df1.columns:\n",
    "        for window in [10, 20, 60]:\n",
    "            # Volatility\n",
    "            df1[f'{company}_Return_volatility_{window}'] = \\\n",
    "                df1[return_col].rolling(window).std()\n",
    "            \n",
    "            # Momentum (average return)\n",
    "            df1[f'{company}_Return_momentum_{window}'] = \\\n",
    "                df1[return_col].rolling(window).mean()\n",
    "            \n",
    "            rolling_count += 2\n",
    "\n",
    "print(f\"   âœ… Company rolling stats: {rolling_count} features\")\n",
    "\n",
    "# C. Spread widening (credit stress indicators)\n",
    "rolling_count = 0\n",
    "for spread in ['Corporate_Bond_Spread', 'High_Yield_Spread', 'TED_Spread']:\n",
    "    if spread in df1.columns:\n",
    "        for window in [20, 60]:\n",
    "            df1[f'{spread}_rolling_mean_{window}'] = df1[spread].rolling(window).mean()\n",
    "            df1[f'{spread}_rolling_max_{window}'] = df1[spread].rolling(window).max()\n",
    "            rolling_count += 2\n",
    "\n",
    "print(f\"   âœ… Spread rolling stats: {rolling_count} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e9c40",
   "metadata": {},
   "source": [
    "3. Critical Interaction Features\n",
    "Based on EDA showing VIX correlates 0.81 with Financial_Stress_Index, create stress composites:\n",
    "\n",
    "Why: Your EDA shows high correlations - interactions capture combined effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eddd2e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/6] Creating interaction features (stress composites)...\n",
      "   âœ… Created 7 interaction features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2510481962.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Credit_Liquidity_Stress'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2510481962.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Market_Credit_Stress'] = df1['VIX'] * df1['Corporate_Bond_Spread']\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2510481962.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Unemployment_Confidence_Stress'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2510481962.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Market_Economy_Divergence'] = df1['SP500_Return'] - df1['GDP_Growth']\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2510481962.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Inflation_Rate_Product'] = df1['CPI_Inflation'] * df1['Federal_Funds_Rate']\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2510481962.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Inverted_Yield_Curve'] = (df1['Yield_Curve_Spread'] < 0).astype(int)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2510481962.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Yield_Curve_Stress'] = df1['Yield_Curve_Spread'].apply(\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4/6] Creating interaction features (stress composites)...\")\n",
    "\n",
    "interaction_count = 0\n",
    "\n",
    "# A. Combined Stress Indices\n",
    "if all(col in df1.columns for col in ['Corporate_Bond_Spread', 'TED_Spread', 'High_Yield_Spread']):\n",
    "    df1['Credit_Liquidity_Stress'] = (\n",
    "        df1['Corporate_Bond_Spread'] * df1['TED_Spread'] * df1['High_Yield_Spread']\n",
    "    )\n",
    "    interaction_count += 1\n",
    "\n",
    "if all(col in df1.columns for col in ['VIX', 'Corporate_Bond_Spread']):\n",
    "    df1['Market_Credit_Stress'] = df1['VIX'] * df1['Corporate_Bond_Spread']\n",
    "    interaction_count += 1\n",
    "\n",
    "if all(col in df1.columns for col in ['Unemployment_Rate', 'Consumer_Confidence']):\n",
    "    df1['Unemployment_Confidence_Stress'] = (\n",
    "        df1['Unemployment_Rate'] * (100 - df1['Consumer_Confidence'])\n",
    "    )\n",
    "    interaction_count += 1\n",
    "\n",
    "# B. Economic divergence\n",
    "if all(col in df1.columns for col in ['SP500_Return', 'GDP_Growth']):\n",
    "    df1['Market_Economy_Divergence'] = df1['SP500_Return'] - df1['GDP_Growth']\n",
    "    interaction_count += 1\n",
    "\n",
    "if all(col in df1.columns for col in ['CPI_Inflation', 'Federal_Funds_Rate']):\n",
    "    df1['Inflation_Rate_Product'] = df1['CPI_Inflation'] * df1['Federal_Funds_Rate']\n",
    "    interaction_count += 1\n",
    "\n",
    "# C. Yield curve analysis\n",
    "if 'Yield_Curve_Spread' in df1.columns:\n",
    "    df1['Inverted_Yield_Curve'] = (df1['Yield_Curve_Spread'] < 0).astype(int)\n",
    "    df1['Yield_Curve_Stress'] = df1['Yield_Curve_Spread'].apply(\n",
    "        lambda x: 1 if x < -0.5 else 0\n",
    "    )\n",
    "    interaction_count += 2\n",
    "\n",
    "print(f\"   âœ… Created {interaction_count} interaction features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45009909",
   "metadata": {},
   "source": [
    "4. Sector Indices (From Your 25 Companies)\n",
    "Based on company list, aggregate by sector:\n",
    "\n",
    "Why: EDA showed sector patterns - financials especially stressed during crises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5226fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/6] Creating sector indices...\n",
      "   âœ… Created 22 sector features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Return'] = df1[return_cols].mean(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Volatility'] = df1[return_cols].std(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Momentum_20'] = df1[f'{sector}_Sector_Return'].rolling(20).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Return'] = df1[return_cols].mean(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Volatility'] = df1[return_cols].std(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Momentum_20'] = df1[f'{sector}_Sector_Return'].rolling(20).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Return'] = df1[return_cols].mean(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Volatility'] = df1[return_cols].std(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Momentum_20'] = df1[f'{sector}_Sector_Return'].rolling(20).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Return'] = df1[return_cols].mean(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Volatility'] = df1[return_cols].std(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Momentum_20'] = df1[f'{sector}_Sector_Return'].rolling(20).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Return'] = df1[return_cols].mean(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Volatility'] = df1[return_cols].std(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Momentum_20'] = df1[f'{sector}_Sector_Return'].rolling(20).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Return'] = df1[return_cols].mean(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Volatility'] = df1[return_cols].std(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Momentum_20'] = df1[f'{sector}_Sector_Return'].rolling(20).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Return'] = df1[return_cols].mean(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Volatility'] = df1[return_cols].std(axis=1)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{sector}_Sector_Momentum_20'] = df1[f'{sector}_Sector_Return'].rolling(20).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1969745594.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Financial_Sector_Stress'] = (\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5/6] Creating sector indices...\")\n",
    "\n",
    "sector_groups = {\n",
    "    'Financial': ['JPM', 'BAC', 'C', 'GS', 'WFC'],\n",
    "    'Tech': ['AAPL', 'MSFT', 'GOOGL', 'NVDA', 'AMZN'],\n",
    "    'Healthcare': ['UNH', 'JNJ'],\n",
    "    'Energy': ['XOM', 'CVX'],\n",
    "    'Consumer_Discretionary': ['TSLA', 'MCD', 'COST', 'DIS'],\n",
    "    'Consumer_Staples': ['WMT', 'PG'],\n",
    "    'Industrial': ['BA', 'CAT', 'LIN', 'HD']\n",
    "}\n",
    "\n",
    "sector_count = 0\n",
    "for sector, stocks in sector_groups.items():\n",
    "    return_cols = [f'{s}_Stock_Return' for s in stocks if f'{s}_Stock_Return' in df1.columns]\n",
    "    \n",
    "    if len(return_cols) > 0:\n",
    "        # Sector average return\n",
    "        df1[f'{sector}_Sector_Return'] = df1[return_cols].mean(axis=1)\n",
    "        sector_count += 1\n",
    "        \n",
    "        # Sector volatility\n",
    "        df1[f'{sector}_Sector_Volatility'] = df1[return_cols].std(axis=1)\n",
    "        sector_count += 1\n",
    "        \n",
    "        # Sector momentum (20-day average)\n",
    "        df1[f'{sector}_Sector_Momentum_20'] = df1[f'{sector}_Sector_Return'].rolling(20).mean()\n",
    "        sector_count += 1\n",
    "\n",
    "# Financial sector stress (special case)\n",
    "if all(col in df1.columns for col in ['Financial_Sector_Volatility', 'Corporate_Bond_Spread']):\n",
    "    df1['Financial_Sector_Stress'] = (\n",
    "        df1['Financial_Sector_Volatility'] * df1['Corporate_Bond_Spread']\n",
    "    )\n",
    "    sector_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {sector_count} sector features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa8d5a",
   "metadata": {},
   "source": [
    "5. Company-Specific Risk Features\n",
    "\n",
    "Why: Individual company stress matters for prediction targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "078f30d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/6] Creating company-specific risk features...\n",
      "   âœ… Created 100 company-specific features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_vs_SP500'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Market_Beta_60'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Drawdown'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2345226557.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Volume_Spike'] = (\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[6/6] Creating company-specific risk features...\")\n",
    "\n",
    "company_feature_count = 0\n",
    "\n",
    "for company in companies:\n",
    "    return_col = f'{company}_Stock_Return'\n",
    "    price_col = f'{company}_Stock_Price'\n",
    "    volume_col = f'{company}_Stock_Volume'\n",
    "    \n",
    "    # A. Relative performance (company vs market)\n",
    "    if return_col in df1.columns and 'SP500_Return' in df1.columns:\n",
    "        df1[f'{company}_vs_SP500'] = (\n",
    "            df1[return_col] - df1['SP500_Return']\n",
    "        )\n",
    "        company_feature_count += 1\n",
    "        \n",
    "        # Beta-like measure (60-day rolling correlation)\n",
    "        df1[f'{company}_Market_Beta_60'] = (\n",
    "            df1[return_col].rolling(60).corr(df1['SP500_Return'])\n",
    "        )\n",
    "        company_feature_count += 1\n",
    "    \n",
    "    # B. Drawdown (distance from recent peak)\n",
    "    if price_col in df1.columns:\n",
    "        rolling_max = df1[price_col].rolling(252, min_periods=1).max()\n",
    "        df1[f'{company}_Drawdown'] = (\n",
    "            (df1[price_col] - rolling_max) / rolling_max * 100\n",
    "        )\n",
    "        company_feature_count += 1\n",
    "    \n",
    "    # C. Volume anomalies\n",
    "    if volume_col in df1.columns:\n",
    "        avg_volume_20 = df1[volume_col].rolling(20).mean()\n",
    "        df1[f'{company}_Volume_Spike'] = (\n",
    "            (df1[volume_col] / avg_volume_20 > 2).astype(int)\n",
    "        )\n",
    "        company_feature_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {company_feature_count} company-specific features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b48ad9",
   "metadata": {},
   "source": [
    "6. Market Regime Features\n",
    "From EDA: 9.6% of days have VIX > 30\n",
    "\n",
    "Why: Identifies different market environments - models can learn regime-specific patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0713896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating market regime features...\n",
      "   âœ… Created 6 regime features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2325897651.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['High_Volatility_Regime'] = (df1['VIX'] > 30).astype(int)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2325897651.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Extreme_Volatility_Regime'] = (df1['VIX'] > 40).astype(int)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2325897651.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Recession_Signal'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2325897651.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Inverted_Curve_Signal'] = (df1['Yield_Curve_Spread'] < 0).astype(int)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2325897651.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Tight_Credit_Regime'] = (df1['Corporate_Bond_Spread'] > spread_75th).astype(int)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2325897651.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Fed_Hiking_Cycle'] = (\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating market regime features...\")\n",
    "\n",
    "regime_count = 0\n",
    "\n",
    "# A. Volatility regimes\n",
    "if 'VIX' in df1.columns:\n",
    "    df1['High_Volatility_Regime'] = (df1['VIX'] > 30).astype(int)\n",
    "    df1['Extreme_Volatility_Regime'] = (df1['VIX'] > 40).astype(int)\n",
    "    regime_count += 2\n",
    "\n",
    "# B. Economic cycle indicators\n",
    "if 'Unemployment_Rate' in df1.columns and 'GDP_Growth' in df1.columns:\n",
    "    df1['Recession_Signal'] = (\n",
    "        ((df1['Unemployment_Rate'] > df1['Unemployment_Rate'].rolling(60).mean()) & \n",
    "         (df1['GDP_Growth'] < 0))\n",
    "    ).astype(int)\n",
    "    regime_count += 1\n",
    "\n",
    "if 'Yield_Curve_Spread' in df1.columns:\n",
    "    df1['Inverted_Curve_Signal'] = (df1['Yield_Curve_Spread'] < 0).astype(int)\n",
    "    regime_count += 1\n",
    "\n",
    "# C. Credit stress regime\n",
    "if 'Corporate_Bond_Spread' in df1.columns:\n",
    "    spread_75th = df1['Corporate_Bond_Spread'].quantile(0.75)\n",
    "    df1['Tight_Credit_Regime'] = (df1['Corporate_Bond_Spread'] > spread_75th).astype(int)\n",
    "    regime_count += 1\n",
    "\n",
    "# D. Rate hike cycle\n",
    "if 'Federal_Funds_Rate' in df1.columns:\n",
    "    df1['Fed_Hiking_Cycle'] = (\n",
    "        df1['Federal_Funds_Rate'] > df1['Federal_Funds_Rate'].shift(60)\n",
    "    ).astype(int)\n",
    "    regime_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {regime_count} regime features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9ad60",
   "metadata": {},
   "source": [
    "Phase 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c43ea81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase1_features = df1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af740c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/2] Creating Exponential Moving Averages (EMA)...\n",
      "   âœ… Created 16 EMA features\n",
      "      Features: ['VIX', 'SP500_Return', 'GDP_Growth', 'Unemployment_Rate']\n",
      "      Spans: [5, 10, 20, 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\4027615470.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 7. EXPONENTIAL MOVING AVERAGES (EMA)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[1/2] Creating Exponential Moving Averages (EMA)...\")\n",
    "\n",
    "# EMA gives more weight to recent observations\n",
    "spans = [5, 10, 20, 60]\n",
    "ema_features = ['VIX', 'SP500_Return', 'GDP_Growth', 'Unemployment_Rate']\n",
    "\n",
    "ema_count = 0\n",
    "for feature in ema_features:\n",
    "    if feature in df1.columns:\n",
    "        for span in spans:\n",
    "            df1[f'{feature}_ema_{span}'] = df1[feature].ewm(span=span, adjust=False).mean()\n",
    "            ema_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {ema_count} EMA features\")\n",
    "print(f\"      Features: {ema_features}\")\n",
    "print(f\"      Spans: {spans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a1f5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/2] Creating Rate of Change features...\n",
      "   âœ… Created 18 Rate of Change features\n",
      "      Features: ['VIX', 'Unemployment_Rate', 'Corporate_Bond_Spread']\n",
      "      Periods: [5, 10, 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_change_{period}'] = df1[feature].diff(period)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_pct_change_{period}'] = df1[feature].pct_change(period) * 100\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_change_{period}'] = df1[feature].diff(period)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_pct_change_{period}'] = df1[feature].pct_change(period) * 100\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_change_{period}'] = df1[feature].diff(period)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_pct_change_{period}'] = df1[feature].pct_change(period) * 100\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_change_{period}'] = df1[feature].diff(period)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_pct_change_{period}'] = df1[feature].pct_change(period) * 100\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_change_{period}'] = df1[feature].diff(period)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_pct_change_{period}'] = df1[feature].pct_change(period) * 100\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_change_{period}'] = df1[feature].diff(period)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_pct_change_{period}'] = df1[feature].pct_change(period) * 100\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_change_{period}'] = df1[feature].diff(period)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_pct_change_{period}'] = df1[feature].pct_change(period) * 100\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_change_{period}'] = df1[feature].diff(period)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_pct_change_{period}'] = df1[feature].pct_change(period) * 100\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_change_{period}'] = df1[feature].diff(period)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1449578172.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_pct_change_{period}'] = df1[feature].pct_change(period) * 100\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 8. RATE OF CHANGE FEATURES (Momentum/Acceleration)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[2/2] Creating Rate of Change features...\")\n",
    "\n",
    "# Momentum / acceleration\n",
    "periods = [5, 10, 20]\n",
    "roc_features = ['VIX', 'Unemployment_Rate', 'Corporate_Bond_Spread']\n",
    "\n",
    "roc_count = 0\n",
    "for feature in roc_features:\n",
    "    if feature in df1.columns:\n",
    "        for period in periods:\n",
    "            # Absolute change\n",
    "            df1[f'{feature}_change_{period}'] = df1[feature].diff(period)\n",
    "            roc_count += 1\n",
    "            \n",
    "            # Percentage change\n",
    "            df1[f'{feature}_pct_change_{period}'] = df1[feature].pct_change(period) * 100\n",
    "            roc_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {roc_count} Rate of Change features\")\n",
    "print(f\"      Features: {roc_features}\")\n",
    "print(f\"      Periods: {periods}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99af0792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ“Š FEATURE ENGINEERING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ðŸ”¹ Initial Features: 97\n",
      "\n",
      "======================================================================\n",
      "PHASE 1: TIME-BASED & DOMAIN-SPECIFIC FEATURES\n",
      "======================================================================\n",
      "Features after Phase 1: 456\n",
      "Features added in Phase 1: 359\n",
      "\n",
      "Phase 1 Breakdown:\n",
      "  âœ“ Economic lag features: 25\n",
      "  âœ“ Market stress lag features: 25\n",
      "  âœ“ Rolling statistics (volatility & momentum): 174\n",
      "    - VIX rolling stats: 12\n",
      "    - Company rolling stats: 150\n",
      "    - Spread rolling stats: 12\n",
      "  âœ“ Interaction features (stress composites): 7\n",
      "  âœ“ Sector indices: 22\n",
      "  âœ“ Company-specific risk features: 100\n",
      "  âœ“ Market regime features: 6\n",
      "\n",
      "======================================================================\n",
      "PHASE 2: ADVANCED TECHNICAL FEATURES\n",
      "======================================================================\n",
      "Features after Phase 2: 490\n",
      "Features added in Phase 2: 34\n",
      "\n",
      "Phase 2 Breakdown:\n",
      "  âœ“ Exponential Moving Averages (EMA): 16\n",
      "  âœ“ Rate of Change features: 18\n",
      "\n",
      "======================================================================\n",
      "OVERALL SUMMARY\n",
      "======================================================================\n",
      "ðŸ“ˆ Total Features Created: 393\n",
      "ðŸ“Š Initial: 97 â†’ Final: 490\n",
      "ðŸ”¢ Percentage Increase: 405.2%\n",
      "\n",
      "======================================================================\n",
      "DATA QUALITY CHECK\n",
      "======================================================================\n",
      "Total Rows: 6,910\n",
      "Total Columns: 490\n",
      "Memory Usage: 25.28 MB\n",
      "\n",
      "Features with Missing Values: 274\n",
      "Total Missing Values: 7,664\n",
      "Max Missing in Single Feature: 143 (GOOGL_Market_Beta_60)\n",
      "\n",
      "======================================================================\n",
      "FEATURE CATEGORIES\n",
      "======================================================================\n",
      "  ðŸ“Œ Lag Features: 50\n",
      "  ðŸ“Œ Rolling Window Features: 24\n",
      "  ðŸ“Œ EMA Features: 16\n",
      "  ðŸ“Œ Sector Features: 22\n",
      "  ðŸ“Œ Regime Features: 5\n",
      "  ðŸ“Œ Interaction Features: 16\n",
      "\n",
      "======================================================================\n",
      "âœ… Feature Engineering Complete!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary of Feature Engineering\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initial state\n",
    "print(f\"\\nðŸ”¹ Initial Features: {initial_features}\")\n",
    "\n",
    "# Phase 1 Summary\n",
    "phase1_added = phase1_features - initial_features\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PHASE 1: TIME-BASED & DOMAIN-SPECIFIC FEATURES\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Features after Phase 1: {phase1_features}\")\n",
    "print(f\"Features added in Phase 1: {phase1_added}\")\n",
    "\n",
    "print(\"\\nPhase 1 Breakdown:\")\n",
    "print(f\"  âœ“ Economic lag features: 25\")\n",
    "print(f\"  âœ“ Market stress lag features: 25\")\n",
    "print(f\"  âœ“ Rolling statistics (volatility & momentum): 174\")\n",
    "print(f\"    - VIX rolling stats: 12\")\n",
    "print(f\"    - Company rolling stats: 150\")\n",
    "print(f\"    - Spread rolling stats: 12\")\n",
    "print(f\"  âœ“ Interaction features (stress composites): 7\")\n",
    "print(f\"  âœ“ Sector indices: 22\")\n",
    "print(f\"  âœ“ Company-specific risk features: 100\")\n",
    "print(f\"  âœ“ Market regime features: 6\")\n",
    "\n",
    "# Phase 2 Summary\n",
    "final_features = df1.shape[1]\n",
    "phase2_added = final_features - phase1_features\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PHASE 2: ADVANCED TECHNICAL FEATURES\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Features after Phase 2: {final_features}\")\n",
    "print(f\"Features added in Phase 2: {phase2_added}\")\n",
    "\n",
    "print(\"\\nPhase 2 Breakdown:\")\n",
    "print(f\"  âœ“ Exponential Moving Averages (EMA): 16\")\n",
    "print(f\"  âœ“ Rate of Change features: 18\")\n",
    "\n",
    "# Overall Summary\n",
    "total_added = final_features - initial_features\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"OVERALL SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"ðŸ“ˆ Total Features Created: {total_added}\")\n",
    "print(f\"ðŸ“Š Initial: {initial_features} â†’ Final: {final_features}\")\n",
    "print(f\"ðŸ”¢ Percentage Increase: {(total_added/initial_features)*100:.1f}%\")\n",
    "\n",
    "# Data quality check\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total Rows: {len(df1):,}\")\n",
    "print(f\"Total Columns: {df1.shape[1]}\")\n",
    "print(f\"Memory Usage: {df1.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_summary = df1.isnull().sum()\n",
    "features_with_missing = missing_summary[missing_summary > 0]\n",
    "print(f\"\\nFeatures with Missing Values: {len(features_with_missing)}\")\n",
    "if len(features_with_missing) > 0:\n",
    "    print(f\"Total Missing Values: {features_with_missing.sum():,}\")\n",
    "    print(f\"Max Missing in Single Feature: {features_with_missing.max():,} ({features_with_missing.idxmax()})\")\n",
    "\n",
    "# Feature categories\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FEATURE CATEGORIES\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "lag_features = [col for col in df1.columns if 'lag' in col.lower()]\n",
    "rolling_features = [col for col in df1.columns if 'rolling' in col.lower()]\n",
    "ema_features = [col for col in df1.columns if 'ema' in col.lower()]\n",
    "sector_features = [col for col in df1.columns if 'sector' in col.lower()]\n",
    "regime_features = [col for col in df1.columns if 'regime' in col.lower() or 'signal' in col.lower()]\n",
    "interaction_features = [col for col in df1.columns if any(x in col.lower() for x in ['stress', 'divergence', 'product', 'inverted', 'curve'])]\n",
    "\n",
    "print(f\"  ðŸ“Œ Lag Features: {len(lag_features)}\")\n",
    "print(f\"  ðŸ“Œ Rolling Window Features: {len(rolling_features)}\")\n",
    "print(f\"  ðŸ“Œ EMA Features: {len(ema_features)}\")\n",
    "print(f\"  ðŸ“Œ Sector Features: {len(sector_features)}\")\n",
    "print(f\"  ðŸ“Œ Regime Features: {len(regime_features)}\")\n",
    "print(f\"  ðŸ“Œ Interaction Features: {len(interaction_features)}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"âœ… Feature Engineering Complete!\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d6a4ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸš€ ADDING HIGH-PRIORITY MISSING FEATURES\n",
      "======================================================================\n",
      "\n",
      "[1/4] Creating rolling correlations...\n",
      "   âœ… Created 12 rolling correlation features\n",
      "\n",
      "[2/4] Creating shock indicators...\n",
      "   âœ… Created 12 shock/deviation features\n",
      "\n",
      "[3/4] Creating Sharpe-like ratios...\n",
      "   âœ… Created 75 Sharpe-like ratio features\n",
      "\n",
      "[4/4] Creating key interaction features...\n",
      "   âœ… Created 7 interaction features\n",
      "\n",
      "======================================================================\n",
      "ðŸ“Š HIGH-PRIORITY FEATURES SUMMARY\n",
      "======================================================================\n",
      "\n",
      "âœ… Feature Engineering Complete!\n",
      "   Features before: 490\n",
      "   New features added: 106\n",
      "   Total features now: 596\n",
      "\n",
      "ðŸ“‹ Feature Breakdown:\n",
      "   â€¢ Rolling correlations: 12\n",
      "   â€¢ Shock indicators: 12\n",
      "   â€¢ Sharpe ratios: 75\n",
      "   â€¢ Interactions: 7\n",
      "   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€   â”€\n",
      "   Total added: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_SP500_VIX_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_SP500_VIX_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_SP500_VIX_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_OilPrice_CPI_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_OilPrice_CPI_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_OilPrice_CPI_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_CorpSpread_HYSpread_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_CorpSpread_HYSpread_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_CorpSpread_HYSpread_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_Financial_Tech_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_Financial_Tech_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'corr_Financial_Tech_{window}'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Shock'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Deviation'] = (df1[feature] - rolling_mean) / (rolling_std + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Shock'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Deviation'] = (df1[feature] - rolling_mean) / (rolling_std + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Shock'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Deviation'] = (df1[feature] - rolling_mean) / (rolling_std + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Shock'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Deviation'] = (df1[feature] - rolling_mean) / (rolling_std + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Shock'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Deviation'] = (df1[feature] - rolling_mean) / (rolling_std + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Shock'] = (\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{feature}_Deviation'] = (df1[feature] - rolling_mean) / (rolling_std + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Stagflation_Risk'] = df1['Federal_Funds_Rate'] * df1['Unemployment_Rate']\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Energy_Burden'] = df1['Oil_Price'] / (df1['GDP_Growth'].abs() + 0.01)\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Market_Stress_Composite'] = df1['Financial_Stress_Index'] * df1['VIX']\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Delta_SP500'] = df1['SP500_Return'].diff()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['Delta_VIX'] = df1['VIX'].diff()\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:134: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['CoMovement_SP500_VIX'] = df1['Delta_SP500'] * df1['Delta_VIX']\n",
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1789211363.py:139: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['RateShock_MarketStress'] = df1['Federal_Funds_Rate_Deviation'].abs() * df1['VIX']\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# ADDITIONAL HIGH-PRIORITY FEATURES\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸš€ ADDING HIGH-PRIORITY MISSING FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "features_before = df1.shape[1]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. ROLLING CORRELATIONS\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[1/4] Creating rolling correlations...\")\n",
    "\n",
    "windows = [30, 60, 90]\n",
    "corr_count = 0\n",
    "\n",
    "# Market correlations\n",
    "if 'SP500_Return' in df1.columns and 'VIX' in df1.columns:\n",
    "    for window in windows:\n",
    "        df1[f'corr_SP500_VIX_{window}'] = (\n",
    "            df1['SP500_Return'].rolling(window).corr(df1['VIX'])\n",
    "        )\n",
    "        corr_count += 1\n",
    "\n",
    "# Economic correlations\n",
    "if 'Oil_Price' in df1.columns and 'CPI_Inflation' in df1.columns:\n",
    "    for window in windows:\n",
    "        df1[f'corr_OilPrice_CPI_{window}'] = (\n",
    "            df1['Oil_Price'].rolling(window).corr(df1['CPI_Inflation'])\n",
    "        )\n",
    "        corr_count += 1\n",
    "\n",
    "# Spread correlations (credit stress)\n",
    "if 'Corporate_Bond_Spread' in df1.columns and 'High_Yield_Spread' in df1.columns:\n",
    "    for window in windows:\n",
    "        df1[f'corr_CorpSpread_HYSpread_{window}'] = (\n",
    "            df1['Corporate_Bond_Spread'].rolling(window).corr(df1['High_Yield_Spread'])\n",
    "        )\n",
    "        corr_count += 1\n",
    "\n",
    "# Sector correlations\n",
    "if 'Financial_Sector_Return' in df1.columns and 'Tech_Sector_Return' in df1.columns:\n",
    "    for window in windows:\n",
    "        df1[f'corr_Financial_Tech_{window}'] = (\n",
    "            df1['Financial_Sector_Return'].rolling(window).corr(df1['Tech_Sector_Return'])\n",
    "        )\n",
    "        corr_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {corr_count} rolling correlation features\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. SHOCK INDICATORS (2-Sigma Deviations)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[2/4] Creating shock indicators...\")\n",
    "\n",
    "features_to_monitor = [\n",
    "    'Federal_Funds_Rate', 'Unemployment_Rate', 'VIX', \n",
    "    'Corporate_Bond_Spread', 'Oil_Price', 'CPI_Inflation'\n",
    "]\n",
    "\n",
    "shock_count = 0\n",
    "window = 30  # 30-day baseline\n",
    "\n",
    "for feature in features_to_monitor:\n",
    "    if feature in df1.columns:\n",
    "        # Calculate rolling statistics\n",
    "        rolling_mean = df1[feature].rolling(window).mean()\n",
    "        rolling_std = df1[feature].rolling(window).std()\n",
    "        \n",
    "        # Binary shock indicator (exceeds 2-sigma)\n",
    "        df1[f'{feature}_Shock'] = (\n",
    "            (df1[feature] - rolling_mean).abs() > 2 * rolling_std\n",
    "        ).astype(int)\n",
    "        shock_count += 1\n",
    "        \n",
    "        # Continuous deviation (how many sigmas away)\n",
    "        df1[f'{feature}_Deviation'] = (df1[feature] - rolling_mean) / (rolling_std + 1e-6)\n",
    "        shock_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {shock_count} shock/deviation features\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. SHARPE-LIKE RATIOS (Risk-Adjusted Returns)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[3/4] Creating Sharpe-like ratios...\")\n",
    "\n",
    "companies = ['AAPL', 'AMZN', 'BA', 'BAC', 'C', 'CAT', 'COST', 'CVX', \n",
    "             'DIS', 'GOOGL', 'GS', 'HD', 'JNJ', 'JPM', 'LIN', 'MCD', \n",
    "             'MSFT', 'NFLX', 'NVDA', 'PG', 'TSLA', 'UNH', 'WFC', 'WMT', 'XOM']\n",
    "\n",
    "sharpe_count = 0\n",
    "\n",
    "for company in companies:\n",
    "    return_col = f'{company}_Stock_Return'\n",
    "    if return_col in df1.columns:\n",
    "        for window in [30, 60, 90]:\n",
    "            mean_return = df1[return_col].rolling(window).mean()\n",
    "            std_return = df1[return_col].rolling(window).std()\n",
    "            \n",
    "            # Sharpe-like: mean return / volatility\n",
    "            df1[f'{company}_Sharpe_{window}'] = mean_return / (std_return + 1e-6)\n",
    "            sharpe_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {sharpe_count} Sharpe-like ratio features\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. KEY INTERACTION FEATURES\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n[4/4] Creating key interaction features...\")\n",
    "\n",
    "interaction_count = 0\n",
    "\n",
    "# Stagflation risk (high rates + high unemployment)\n",
    "if 'Federal_Funds_Rate' in df1.columns and 'Unemployment_Rate' in df1.columns:\n",
    "    df1['Stagflation_Risk'] = df1['Federal_Funds_Rate'] * df1['Unemployment_Rate']\n",
    "    interaction_count += 1\n",
    "\n",
    "# Energy burden on growth\n",
    "if 'Oil_Price' in df1.columns and 'GDP_Growth' in df1.columns:\n",
    "    df1['Energy_Burden'] = df1['Oil_Price'] / (df1['GDP_Growth'].abs() + 0.01)\n",
    "    interaction_count += 1\n",
    "\n",
    "# Composite stress (Financial Stress Ã— VIX)\n",
    "if 'Financial_Stress_Index' in df1.columns and 'VIX' in df1.columns:\n",
    "    df1['Market_Stress_Composite'] = df1['Financial_Stress_Index'] * df1['VIX']\n",
    "    interaction_count += 1\n",
    "\n",
    "# Co-movement indicator (changes in SP500 Ã— changes in VIX)\n",
    "if 'SP500_Return' in df1.columns and 'VIX' in df1.columns:\n",
    "    df1['Delta_SP500'] = df1['SP500_Return'].diff()\n",
    "    df1['Delta_VIX'] = df1['VIX'].diff()\n",
    "    df1['CoMovement_SP500_VIX'] = df1['Delta_SP500'] * df1['Delta_VIX']\n",
    "    interaction_count += 3\n",
    "\n",
    "# Interest rate shock Ã— Market volatility\n",
    "if 'Federal_Funds_Rate_Deviation' in df1.columns and 'VIX' in df1.columns:\n",
    "    df1['RateShock_MarketStress'] = df1['Federal_Funds_Rate_Deviation'].abs() * df1['VIX']\n",
    "    interaction_count += 1\n",
    "\n",
    "print(f\"   âœ… Created {interaction_count} interaction features\")\n",
    "\n",
    "# ===================================================================\n",
    "# SUMMARY\n",
    "# ===================================================================\n",
    "\n",
    "features_after = df1.shape[1]\n",
    "new_features = features_after - features_before\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š HIGH-PRIORITY FEATURES SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nâœ… Feature Engineering Complete!\")\n",
    "print(f\"   Features before: {features_before}\")\n",
    "print(f\"   New features added: {new_features}\")\n",
    "print(f\"   Total features now: {features_after}\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Feature Breakdown:\")\n",
    "print(f\"   â€¢ Rolling correlations: {corr_count}\")\n",
    "print(f\"   â€¢ Shock indicators: {shock_count}\")\n",
    "print(f\"   â€¢ Sharpe ratios: {sharpe_count}\")\n",
    "print(f\"   â€¢ Interactions: {interaction_count}\")\n",
    "print(f\"   â”€\" * 35)\n",
    "print(f\"   Total added: {corr_count + shock_count + sharpe_count + interaction_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53711796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File saved: financial_data_engineered_complete.csv\n"
     ]
    }
   ],
   "source": [
    "df1.to_csv('financial_data_engineered_complete.csv')\n",
    "\n",
    "print(\"âœ… File saved: financial_data_engineered_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d59d475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDP_Growth_lag1: 1 missing values\n",
      "GDP_Growth_lag5: 5 missing values\n",
      "GDP_Growth_lag10: 10 missing values\n",
      "GDP_Growth_lag20: 20 missing values\n",
      "GDP_Growth_lag60: 60 missing values\n",
      "Unemployment_Rate_lag1: 1 missing values\n",
      "Unemployment_Rate_lag5: 5 missing values\n",
      "Unemployment_Rate_lag10: 10 missing values\n",
      "Unemployment_Rate_lag20: 20 missing values\n",
      "Unemployment_Rate_lag60: 60 missing values\n",
      "CPI_Inflation_lag1: 1 missing values\n",
      "CPI_Inflation_lag5: 5 missing values\n",
      "CPI_Inflation_lag10: 10 missing values\n",
      "CPI_Inflation_lag20: 20 missing values\n",
      "CPI_Inflation_lag60: 60 missing values\n",
      "Federal_Funds_Rate_lag1: 1 missing values\n",
      "Federal_Funds_Rate_lag5: 5 missing values\n",
      "Federal_Funds_Rate_lag10: 10 missing values\n",
      "Federal_Funds_Rate_lag20: 20 missing values\n",
      "Federal_Funds_Rate_lag60: 60 missing values\n",
      "Consumer_Confidence_lag1: 1 missing values\n",
      "Consumer_Confidence_lag5: 5 missing values\n",
      "Consumer_Confidence_lag10: 10 missing values\n",
      "Consumer_Confidence_lag20: 20 missing values\n",
      "Consumer_Confidence_lag60: 60 missing values\n",
      "VIX_lag1: 1 missing values\n",
      "VIX_lag2: 2 missing values\n",
      "VIX_lag3: 3 missing values\n",
      "VIX_lag5: 5 missing values\n",
      "VIX_lag10: 10 missing values\n",
      "Corporate_Bond_Spread_lag1: 1 missing values\n",
      "Corporate_Bond_Spread_lag2: 2 missing values\n",
      "Corporate_Bond_Spread_lag3: 3 missing values\n",
      "Corporate_Bond_Spread_lag5: 5 missing values\n",
      "Corporate_Bond_Spread_lag10: 10 missing values\n",
      "TED_Spread_lag1: 1 missing values\n",
      "TED_Spread_lag2: 2 missing values\n",
      "TED_Spread_lag3: 3 missing values\n",
      "TED_Spread_lag5: 5 missing values\n",
      "TED_Spread_lag10: 10 missing values\n",
      "High_Yield_Spread_lag1: 1 missing values\n",
      "High_Yield_Spread_lag2: 2 missing values\n",
      "High_Yield_Spread_lag3: 3 missing values\n",
      "High_Yield_Spread_lag5: 5 missing values\n",
      "High_Yield_Spread_lag10: 10 missing values\n",
      "Financial_Stress_Index_lag1: 1 missing values\n",
      "Financial_Stress_Index_lag2: 2 missing values\n",
      "Financial_Stress_Index_lag3: 3 missing values\n",
      "Financial_Stress_Index_lag5: 5 missing values\n",
      "Financial_Stress_Index_lag10: 10 missing values\n",
      "VIX_rolling_mean_5: 4 missing values\n",
      "VIX_rolling_std_5: 4 missing values\n",
      "VIX_rolling_max_5: 4 missing values\n",
      "VIX_rolling_mean_10: 9 missing values\n",
      "VIX_rolling_std_10: 9 missing values\n",
      "VIX_rolling_max_10: 9 missing values\n",
      "VIX_rolling_mean_20: 19 missing values\n",
      "VIX_rolling_std_20: 19 missing values\n",
      "VIX_rolling_max_20: 19 missing values\n",
      "VIX_rolling_mean_60: 59 missing values\n",
      "VIX_rolling_std_60: 59 missing values\n",
      "VIX_rolling_max_60: 59 missing values\n",
      "AAPL_Return_volatility_10: 9 missing values\n",
      "AAPL_Return_momentum_10: 9 missing values\n",
      "AAPL_Return_volatility_20: 19 missing values\n",
      "AAPL_Return_momentum_20: 19 missing values\n",
      "AAPL_Return_volatility_60: 59 missing values\n",
      "AAPL_Return_momentum_60: 59 missing values\n",
      "AMZN_Return_volatility_10: 9 missing values\n",
      "AMZN_Return_momentum_10: 9 missing values\n",
      "AMZN_Return_volatility_20: 19 missing values\n",
      "AMZN_Return_momentum_20: 19 missing values\n",
      "AMZN_Return_volatility_60: 59 missing values\n",
      "AMZN_Return_momentum_60: 59 missing values\n",
      "BA_Return_volatility_10: 9 missing values\n",
      "BA_Return_momentum_10: 9 missing values\n",
      "BA_Return_volatility_20: 19 missing values\n",
      "BA_Return_momentum_20: 19 missing values\n",
      "BA_Return_volatility_60: 59 missing values\n",
      "BA_Return_momentum_60: 59 missing values\n",
      "BAC_Return_volatility_10: 9 missing values\n",
      "BAC_Return_momentum_10: 9 missing values\n",
      "BAC_Return_volatility_20: 19 missing values\n",
      "BAC_Return_momentum_20: 19 missing values\n",
      "BAC_Return_volatility_60: 59 missing values\n",
      "BAC_Return_momentum_60: 59 missing values\n",
      "C_Return_volatility_10: 9 missing values\n",
      "C_Return_momentum_10: 9 missing values\n",
      "C_Return_volatility_20: 19 missing values\n",
      "C_Return_momentum_20: 19 missing values\n",
      "C_Return_volatility_60: 59 missing values\n",
      "C_Return_momentum_60: 59 missing values\n",
      "CAT_Return_volatility_10: 9 missing values\n",
      "CAT_Return_momentum_10: 9 missing values\n",
      "CAT_Return_volatility_20: 19 missing values\n",
      "CAT_Return_momentum_20: 19 missing values\n",
      "CAT_Return_volatility_60: 59 missing values\n",
      "CAT_Return_momentum_60: 59 missing values\n",
      "COST_Return_volatility_10: 9 missing values\n",
      "COST_Return_momentum_10: 9 missing values\n",
      "COST_Return_volatility_20: 19 missing values\n",
      "COST_Return_momentum_20: 19 missing values\n",
      "COST_Return_volatility_60: 59 missing values\n",
      "COST_Return_momentum_60: 59 missing values\n",
      "CVX_Return_volatility_10: 9 missing values\n",
      "CVX_Return_momentum_10: 9 missing values\n",
      "CVX_Return_volatility_20: 19 missing values\n",
      "CVX_Return_momentum_20: 19 missing values\n",
      "CVX_Return_volatility_60: 59 missing values\n",
      "CVX_Return_momentum_60: 59 missing values\n",
      "DIS_Return_volatility_10: 9 missing values\n",
      "DIS_Return_momentum_10: 9 missing values\n",
      "DIS_Return_volatility_20: 19 missing values\n",
      "DIS_Return_momentum_20: 19 missing values\n",
      "DIS_Return_volatility_60: 59 missing values\n",
      "DIS_Return_momentum_60: 59 missing values\n",
      "GOOGL_Return_volatility_10: 9 missing values\n",
      "GOOGL_Return_momentum_10: 9 missing values\n",
      "GOOGL_Return_volatility_20: 19 missing values\n",
      "GOOGL_Return_momentum_20: 19 missing values\n",
      "GOOGL_Return_volatility_60: 59 missing values\n",
      "GOOGL_Return_momentum_60: 59 missing values\n",
      "GS_Return_volatility_10: 9 missing values\n",
      "GS_Return_momentum_10: 9 missing values\n",
      "GS_Return_volatility_20: 19 missing values\n",
      "GS_Return_momentum_20: 19 missing values\n",
      "GS_Return_volatility_60: 59 missing values\n",
      "GS_Return_momentum_60: 59 missing values\n",
      "HD_Return_volatility_10: 9 missing values\n",
      "HD_Return_momentum_10: 9 missing values\n",
      "HD_Return_volatility_20: 19 missing values\n",
      "HD_Return_momentum_20: 19 missing values\n",
      "HD_Return_volatility_60: 59 missing values\n",
      "HD_Return_momentum_60: 59 missing values\n",
      "JNJ_Return_volatility_10: 9 missing values\n",
      "JNJ_Return_momentum_10: 9 missing values\n",
      "JNJ_Return_volatility_20: 19 missing values\n",
      "JNJ_Return_momentum_20: 19 missing values\n",
      "JNJ_Return_volatility_60: 59 missing values\n",
      "JNJ_Return_momentum_60: 59 missing values\n",
      "JPM_Return_volatility_10: 9 missing values\n",
      "JPM_Return_momentum_10: 9 missing values\n",
      "JPM_Return_volatility_20: 19 missing values\n",
      "JPM_Return_momentum_20: 19 missing values\n",
      "JPM_Return_volatility_60: 59 missing values\n",
      "JPM_Return_momentum_60: 59 missing values\n",
      "LIN_Return_volatility_10: 9 missing values\n",
      "LIN_Return_momentum_10: 9 missing values\n",
      "LIN_Return_volatility_20: 19 missing values\n",
      "LIN_Return_momentum_20: 19 missing values\n",
      "LIN_Return_volatility_60: 59 missing values\n",
      "LIN_Return_momentum_60: 59 missing values\n",
      "MCD_Return_volatility_10: 9 missing values\n",
      "MCD_Return_momentum_10: 9 missing values\n",
      "MCD_Return_volatility_20: 19 missing values\n",
      "MCD_Return_momentum_20: 19 missing values\n",
      "MCD_Return_volatility_60: 59 missing values\n",
      "MCD_Return_momentum_60: 59 missing values\n",
      "MSFT_Return_volatility_10: 9 missing values\n",
      "MSFT_Return_momentum_10: 9 missing values\n",
      "MSFT_Return_volatility_20: 19 missing values\n",
      "MSFT_Return_momentum_20: 19 missing values\n",
      "MSFT_Return_volatility_60: 59 missing values\n",
      "MSFT_Return_momentum_60: 59 missing values\n",
      "NFLX_Return_volatility_10: 9 missing values\n",
      "NFLX_Return_momentum_10: 9 missing values\n",
      "NFLX_Return_volatility_20: 19 missing values\n",
      "NFLX_Return_momentum_20: 19 missing values\n",
      "NFLX_Return_volatility_60: 59 missing values\n",
      "NFLX_Return_momentum_60: 59 missing values\n",
      "NVDA_Return_volatility_10: 9 missing values\n",
      "NVDA_Return_momentum_10: 9 missing values\n",
      "NVDA_Return_volatility_20: 19 missing values\n",
      "NVDA_Return_momentum_20: 19 missing values\n",
      "NVDA_Return_volatility_60: 59 missing values\n",
      "NVDA_Return_momentum_60: 59 missing values\n",
      "PG_Return_volatility_10: 9 missing values\n",
      "PG_Return_momentum_10: 9 missing values\n",
      "PG_Return_volatility_20: 19 missing values\n",
      "PG_Return_momentum_20: 19 missing values\n",
      "PG_Return_volatility_60: 59 missing values\n",
      "PG_Return_momentum_60: 59 missing values\n",
      "TSLA_Return_volatility_10: 9 missing values\n",
      "TSLA_Return_momentum_10: 9 missing values\n",
      "TSLA_Return_volatility_20: 19 missing values\n",
      "TSLA_Return_momentum_20: 19 missing values\n",
      "TSLA_Return_volatility_60: 59 missing values\n",
      "TSLA_Return_momentum_60: 59 missing values\n",
      "UNH_Return_volatility_10: 9 missing values\n",
      "UNH_Return_momentum_10: 9 missing values\n",
      "UNH_Return_volatility_20: 19 missing values\n",
      "UNH_Return_momentum_20: 19 missing values\n",
      "UNH_Return_volatility_60: 59 missing values\n",
      "UNH_Return_momentum_60: 59 missing values\n",
      "WFC_Return_volatility_10: 9 missing values\n",
      "WFC_Return_momentum_10: 9 missing values\n",
      "WFC_Return_volatility_20: 19 missing values\n",
      "WFC_Return_momentum_20: 19 missing values\n",
      "WFC_Return_volatility_60: 59 missing values\n",
      "WFC_Return_momentum_60: 59 missing values\n",
      "WMT_Return_volatility_10: 9 missing values\n",
      "WMT_Return_momentum_10: 9 missing values\n",
      "WMT_Return_volatility_20: 19 missing values\n",
      "WMT_Return_momentum_20: 19 missing values\n",
      "WMT_Return_volatility_60: 59 missing values\n",
      "WMT_Return_momentum_60: 59 missing values\n",
      "XOM_Return_volatility_10: 9 missing values\n",
      "XOM_Return_momentum_10: 9 missing values\n",
      "XOM_Return_volatility_20: 19 missing values\n",
      "XOM_Return_momentum_20: 19 missing values\n",
      "XOM_Return_volatility_60: 59 missing values\n",
      "XOM_Return_momentum_60: 59 missing values\n",
      "Corporate_Bond_Spread_rolling_mean_20: 19 missing values\n",
      "Corporate_Bond_Spread_rolling_max_20: 19 missing values\n",
      "Corporate_Bond_Spread_rolling_mean_60: 59 missing values\n",
      "Corporate_Bond_Spread_rolling_max_60: 59 missing values\n",
      "High_Yield_Spread_rolling_mean_20: 19 missing values\n",
      "High_Yield_Spread_rolling_max_20: 19 missing values\n",
      "High_Yield_Spread_rolling_mean_60: 59 missing values\n",
      "High_Yield_Spread_rolling_max_60: 59 missing values\n",
      "TED_Spread_rolling_mean_20: 19 missing values\n",
      "TED_Spread_rolling_max_20: 19 missing values\n",
      "TED_Spread_rolling_mean_60: 59 missing values\n",
      "TED_Spread_rolling_max_60: 59 missing values\n",
      "Financial_Sector_Momentum_20: 19 missing values\n",
      "Tech_Sector_Momentum_20: 19 missing values\n",
      "Healthcare_Sector_Momentum_20: 19 missing values\n",
      "Energy_Sector_Momentum_20: 19 missing values\n",
      "Consumer_Discretionary_Sector_Momentum_20: 19 missing values\n",
      "Consumer_Staples_Sector_Momentum_20: 19 missing values\n",
      "Industrial_Sector_Momentum_20: 19 missing values\n",
      "AAPL_Market_Beta_60: 59 missing values\n",
      "AMZN_Market_Beta_60: 59 missing values\n",
      "BA_Market_Beta_60: 59 missing values\n",
      "BAC_Market_Beta_60: 59 missing values\n",
      "C_Market_Beta_60: 59 missing values\n",
      "CAT_Market_Beta_60: 59 missing values\n",
      "COST_Market_Beta_60: 59 missing values\n",
      "CVX_Market_Beta_60: 59 missing values\n",
      "DIS_Market_Beta_60: 59 missing values\n",
      "GOOGL_Market_Beta_60: 143 missing values\n",
      "GS_Market_Beta_60: 59 missing values\n",
      "HD_Market_Beta_60: 59 missing values\n",
      "JNJ_Market_Beta_60: 59 missing values\n",
      "JPM_Market_Beta_60: 59 missing values\n",
      "LIN_Market_Beta_60: 59 missing values\n",
      "MCD_Market_Beta_60: 59 missing values\n",
      "MSFT_Market_Beta_60: 59 missing values\n",
      "NFLX_Market_Beta_60: 96 missing values\n",
      "NVDA_Market_Beta_60: 59 missing values\n",
      "PG_Market_Beta_60: 59 missing values\n",
      "TSLA_Market_Beta_60: 108 missing values\n",
      "UNH_Market_Beta_60: 59 missing values\n",
      "WFC_Market_Beta_60: 59 missing values\n",
      "WMT_Market_Beta_60: 59 missing values\n",
      "XOM_Market_Beta_60: 59 missing values\n",
      "VIX_change_5: 5 missing values\n",
      "VIX_pct_change_5: 5 missing values\n",
      "VIX_change_10: 10 missing values\n",
      "VIX_pct_change_10: 10 missing values\n",
      "VIX_change_20: 20 missing values\n",
      "VIX_pct_change_20: 20 missing values\n",
      "Unemployment_Rate_change_5: 5 missing values\n",
      "Unemployment_Rate_pct_change_5: 5 missing values\n",
      "Unemployment_Rate_change_10: 10 missing values\n",
      "Unemployment_Rate_pct_change_10: 10 missing values\n",
      "Unemployment_Rate_change_20: 20 missing values\n",
      "Unemployment_Rate_pct_change_20: 20 missing values\n",
      "Corporate_Bond_Spread_change_5: 5 missing values\n",
      "Corporate_Bond_Spread_pct_change_5: 5 missing values\n",
      "Corporate_Bond_Spread_change_10: 10 missing values\n",
      "Corporate_Bond_Spread_pct_change_10: 10 missing values\n",
      "Corporate_Bond_Spread_change_20: 20 missing values\n",
      "Corporate_Bond_Spread_pct_change_20: 20 missing values\n",
      "corr_SP500_VIX_30: 29 missing values\n",
      "corr_SP500_VIX_60: 59 missing values\n",
      "corr_SP500_VIX_90: 89 missing values\n",
      "corr_OilPrice_CPI_30: 97 missing values\n",
      "corr_OilPrice_CPI_60: 59 missing values\n",
      "corr_OilPrice_CPI_90: 89 missing values\n",
      "corr_CorpSpread_HYSpread_30: 29 missing values\n",
      "corr_CorpSpread_HYSpread_60: 59 missing values\n",
      "corr_CorpSpread_HYSpread_90: 89 missing values\n",
      "corr_Financial_Tech_30: 29 missing values\n",
      "corr_Financial_Tech_60: 59 missing values\n",
      "corr_Financial_Tech_90: 89 missing values\n",
      "Federal_Funds_Rate_Deviation: 29 missing values\n",
      "Unemployment_Rate_Deviation: 29 missing values\n",
      "VIX_Deviation: 29 missing values\n",
      "Corporate_Bond_Spread_Deviation: 29 missing values\n",
      "Oil_Price_Deviation: 29 missing values\n",
      "CPI_Inflation_Deviation: 29 missing values\n",
      "AAPL_Sharpe_30: 29 missing values\n",
      "AAPL_Sharpe_60: 59 missing values\n",
      "AAPL_Sharpe_90: 89 missing values\n",
      "AMZN_Sharpe_30: 29 missing values\n",
      "AMZN_Sharpe_60: 59 missing values\n",
      "AMZN_Sharpe_90: 89 missing values\n",
      "BA_Sharpe_30: 29 missing values\n",
      "BA_Sharpe_60: 59 missing values\n",
      "BA_Sharpe_90: 89 missing values\n",
      "BAC_Sharpe_30: 29 missing values\n",
      "BAC_Sharpe_60: 59 missing values\n",
      "BAC_Sharpe_90: 89 missing values\n",
      "C_Sharpe_30: 29 missing values\n",
      "C_Sharpe_60: 59 missing values\n",
      "C_Sharpe_90: 89 missing values\n",
      "CAT_Sharpe_30: 29 missing values\n",
      "CAT_Sharpe_60: 59 missing values\n",
      "CAT_Sharpe_90: 89 missing values\n",
      "COST_Sharpe_30: 29 missing values\n",
      "COST_Sharpe_60: 59 missing values\n",
      "COST_Sharpe_90: 89 missing values\n",
      "CVX_Sharpe_30: 29 missing values\n",
      "CVX_Sharpe_60: 59 missing values\n",
      "CVX_Sharpe_90: 89 missing values\n",
      "DIS_Sharpe_30: 29 missing values\n",
      "DIS_Sharpe_60: 59 missing values\n",
      "DIS_Sharpe_90: 89 missing values\n",
      "GOOGL_Sharpe_30: 29 missing values\n",
      "GOOGL_Sharpe_60: 59 missing values\n",
      "GOOGL_Sharpe_90: 89 missing values\n",
      "GS_Sharpe_30: 29 missing values\n",
      "GS_Sharpe_60: 59 missing values\n",
      "GS_Sharpe_90: 89 missing values\n",
      "HD_Sharpe_30: 29 missing values\n",
      "HD_Sharpe_60: 59 missing values\n",
      "HD_Sharpe_90: 89 missing values\n",
      "JNJ_Sharpe_30: 29 missing values\n",
      "JNJ_Sharpe_60: 59 missing values\n",
      "JNJ_Sharpe_90: 89 missing values\n",
      "JPM_Sharpe_30: 29 missing values\n",
      "JPM_Sharpe_60: 59 missing values\n",
      "JPM_Sharpe_90: 89 missing values\n",
      "LIN_Sharpe_30: 29 missing values\n",
      "LIN_Sharpe_60: 59 missing values\n",
      "LIN_Sharpe_90: 89 missing values\n",
      "MCD_Sharpe_30: 29 missing values\n",
      "MCD_Sharpe_60: 59 missing values\n",
      "MCD_Sharpe_90: 89 missing values\n",
      "MSFT_Sharpe_30: 29 missing values\n",
      "MSFT_Sharpe_60: 59 missing values\n",
      "MSFT_Sharpe_90: 89 missing values\n",
      "NFLX_Sharpe_30: 29 missing values\n",
      "NFLX_Sharpe_60: 59 missing values\n",
      "NFLX_Sharpe_90: 89 missing values\n",
      "NVDA_Sharpe_30: 29 missing values\n",
      "NVDA_Sharpe_60: 59 missing values\n",
      "NVDA_Sharpe_90: 89 missing values\n",
      "PG_Sharpe_30: 29 missing values\n",
      "PG_Sharpe_60: 59 missing values\n",
      "PG_Sharpe_90: 89 missing values\n",
      "TSLA_Sharpe_30: 29 missing values\n",
      "TSLA_Sharpe_60: 59 missing values\n",
      "TSLA_Sharpe_90: 89 missing values\n",
      "UNH_Sharpe_30: 29 missing values\n",
      "UNH_Sharpe_60: 59 missing values\n",
      "UNH_Sharpe_90: 89 missing values\n",
      "WFC_Sharpe_30: 29 missing values\n",
      "WFC_Sharpe_60: 59 missing values\n",
      "WFC_Sharpe_90: 89 missing values\n",
      "WMT_Sharpe_30: 29 missing values\n",
      "WMT_Sharpe_60: 59 missing values\n",
      "WMT_Sharpe_90: 89 missing values\n",
      "XOM_Sharpe_30: 29 missing values\n",
      "XOM_Sharpe_60: 59 missing values\n",
      "XOM_Sharpe_90: 89 missing values\n",
      "Delta_SP500: 1 missing values\n",
      "Delta_VIX: 1 missing values\n",
      "CoMovement_SP500_VIX: 1 missing values\n",
      "RateShock_MarketStress: 29 missing values\n"
     ]
    }
   ],
   "source": [
    "missing_cols = df1.isnull().sum()\n",
    "missing_cols = missing_cols[missing_cols > 0]   # filter only columns with missing values\n",
    "\n",
    "for col, count in missing_cols.items():\n",
    "    print(f\"{col}: {count} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35657c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/4] Forward filling economic indicators...\n",
      "   Applied to 59 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2568383118.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df1_clean[economic_features] = df1_clean[economic_features].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "df1_clean = df1.copy()\n",
    "# ----------------------------------------\n",
    "# STRATEGY 1: Forward Fill - Economic & Market Indicators\n",
    "# ----------------------------------------\n",
    "# These change slowly, so carrying forward is realistic\n",
    "economic_features = [col for col in df1.columns if any(x in col for x in [\n",
    "    'GDP', 'CPI', 'Unemployment', 'Federal_Funds', 'Consumer_Confidence',\n",
    "    'Treasury', 'Oil_Price', 'Trade_Balance'\n",
    "])]\n",
    "\n",
    "print(f\"\\n[1/4] Forward filling economic indicators...\")\n",
    "df1_clean[economic_features] = df1_clean[economic_features].fillna(method='ffill')\n",
    "print(f\"   Applied to {len(economic_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec606a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_clean = df1_clean.rename(columns={'Unnamed: 0': 'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b207000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/4] Forward filling lag features...\n",
      "   Applied to 50 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\1774666875.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df1_clean[lag_features] = df1_clean[lag_features].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# STRATEGY 2: Forward Fill - Lag Features\n",
    "# ----------------------------------------\n",
    "# Lags by definition use past values\n",
    "lag_features = [col for col in df1.columns if '_lag' in col]\n",
    "\n",
    "print(f\"\\n[2/4] Forward filling lag features...\")\n",
    "df1_clean[lag_features] = df1_clean[lag_features].fillna(method='ffill')\n",
    "print(f\"   Applied to {len(lag_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ea06cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/4] Forward filling rolling statistics...\n",
      "   Applied to 174 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2393821157.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df1_clean[rolling_features] = df1_clean[rolling_features].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# STRATEGY 3: Forward Fill - Rolling Stats\n",
    "# ----------------------------------------\n",
    "# Rolling windows need initial warm-up period\n",
    "rolling_features = [col for col in df1.columns if any(x in col for x in [\n",
    "    'rolling_mean', 'rolling_std', 'rolling_max', 'volatility', 'momentum'\n",
    "])]\n",
    "\n",
    "print(f\"\\n[3/4] Forward filling rolling statistics...\")\n",
    "df1_clean[rolling_features] = df1_clean[rolling_features].fillna(method='ffill')\n",
    "print(f\"   Applied to {len(rolling_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39e4faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/4] Filling remaining features...\n",
      "\n",
      "âœ… Cleaning complete!\n",
      "   Original rows: 6,910\n",
      "   Missing values: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akulc\\AppData\\Local\\Temp\\ipykernel_17480\\2346964131.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df1_clean = df1_clean.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# STRATEGY 4: Forward + Backward Fill - Everything Else\n",
    "# ----------------------------------------\n",
    "print(f\"\\n[4/4] Filling remaining features...\")\n",
    "df1_clean = df1_clean.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Final dropna for any stubborn NaN\n",
    "#rows_before = len(df1_clean)\n",
    "#df1_clean = df1_clean.dropna()\n",
    "#rows_after = len(df1_clean)\n",
    "\n",
    "print(f\"\\nâœ… Cleaning complete!\")\n",
    "print(f\"   Original rows: {len(df1):,}\")\n",
    "#print(f\"   Final rows: {rows_after:,}\")\n",
    "#print(f\"   Rows dropped: {rows_before - rows_after:,}\")\n",
    "#print(f\"   Retention: {(rows_after/len(df1))*100:.2f}%\")\n",
    "print(f\"   Missing values: {df1_clean.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac4e5b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File saved: all_features.csv\n"
     ]
    }
   ],
   "source": [
    "df1_clean.to_csv('all_features.csv')\n",
    "\n",
    "print(\"âœ… File saved: all_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89b89f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'GDP_Growth', 'CPI_Inflation', 'Unemployment_Rate',\n",
       "       'Federal_Funds_Rate', 'Yield_Curve_Spread', 'Consumer_Confidence',\n",
       "       'Oil_Price', 'Trade_Balance', 'Corporate_Bond_Spread',\n",
       "       ...\n",
       "       'XOM_Sharpe_30', 'XOM_Sharpe_60', 'XOM_Sharpe_90', 'Stagflation_Risk',\n",
       "       'Energy_Burden', 'Market_Stress_Composite', 'Delta_SP500', 'Delta_VIX',\n",
       "       'CoMovement_SP500_VIX', 'RateShock_MarketStress'],\n",
       "      dtype='object', length=596)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a288759d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6910, 596)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_clean.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
